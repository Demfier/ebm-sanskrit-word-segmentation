{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import normalize\n",
    "input_path1 ='/home/prithvi/Downloads/large_matrix_from_srinivas/main_x_list.p'\n",
    "input_path2 ='/home/prithvi/Downloads/large_matrix_from_srinivas/main_lemma_list.p'\n",
    "input_path3 ='/home/prithvi/Downloads/large_matrix_from_srinivas/main_cng_list.p'\n",
    "input_path4 ='/home/prithvi/Downloads/large_matrix_from_srinivas/main_mod_list.p'\n",
    "A=pickle.load(open(\"/home/prithvi/Downloads/large_matrix_from_srinivas/csr_sparse_matrix.p\" , 'rb'))\n",
    "A_normalized = normalize(A, norm='l1', axis=1)\n",
    "main_x_list = pickle.load(open(input_path1, \"rb\"))\n",
    "main_lemma_list = pickle.load(open(input_path2, \"rb\"))\n",
    "main_cng_list= pickle.load(open(input_path3, \"rb\"))\n",
    "main_mod_list = pickle.load(open(input_path4, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "input_path ='/home/prithvi/Downloads/lemmas_data'\n",
    "files_1=set(sorted(os.listdir(input_path)))\n",
    "files_1 =list(files_1)\n",
    "d=[]\n",
    "for i,each1 in enumerate(files_1):\n",
    "    path = input_path+'/' +each1\n",
    "    d.append((pickle.load(open(path, \"rb\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path ='/home/prithvi/Downloads/lemmas_data_1'\n",
    "files_1=set(sorted(os.listdir(input_path)))\n",
    "files_1 =list(files_1)\n",
    "d1=[]\n",
    "for i,each1 in enumerate(files_1):\n",
    "    path = input_path+'/' +each1\n",
    "    d1.append((pickle.load(open(path, \"rb\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path ='/home/prithvi/Downloads/intersect'\n",
    "files_1=set(sorted(os.listdir(input_path)))\n",
    "files_1 =list(files_1)\n",
    "result=[]\n",
    "for i,each1 in enumerate(files_1):\n",
    "    path = input_path+'/' +each1\n",
    "    result.append((pickle.load(open(path, \"rb\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4926"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'lemmas': [[u'vac'], [u'na']], u'sentence': u'ucyate na   '},\n",
       " {u'keys': [[0, 4], [0]],\n",
       "  u'lemmas': [[u'vac', u'uc'], [u'tad'], [u'na']],\n",
       "  u'sentence': u'ucyate na   '}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "greedy_paths=[]\n",
    "optimal_paths=[]\n",
    "# input_path ='/home/prithvi/Downloads/extract/extras/all_dcs_lemmas_matrix.p'\n",
    "# input_load = pickle.load(open(input_path, \"rb\"))\n",
    "class beamsearch:\n",
    "    def __init__(self,k,levels,di):\n",
    "        self.k=k\n",
    "        self.levels = levels  \n",
    "        self.nodes_list=di\n",
    "        self.k_paths_greedy=self.top_k_paths_greedy(self.nodes_list,k)\n",
    "        self.k_paths_optimal,self.p_values=self.top_k_paths_optimal(self.nodes_list,k)\n",
    "    def top_k_paths_greedy(self,l,k):\n",
    "        s = [[] for _ in range(k)]\n",
    "        for i in range(0,len(l)):\n",
    "            if i==0:\n",
    "                temp = []\n",
    "                if(len(l[i])>k):\n",
    "                    v = random.sample(range(0,len(l[i])),k)\n",
    "                    for j in v:\n",
    "                        temp.append([l[i][j]])\n",
    "                else:\n",
    "                    for j in range(0,len(l[i])):\n",
    "                        temp.append([l[i][j]])\n",
    "                s=temp\n",
    "            else:\n",
    "                count = 0\n",
    "                for m in s:\n",
    "                    if m:\n",
    "                        count+=1\n",
    "                t = np.zeros(shape=(count,len(l[i]))) \n",
    "                for p in range(0,t.shape[0]):\n",
    "                    for q in range(0,t.shape[1]):\n",
    "                        t[p,q]=A_normalized[s[p][-1],l[i][q]]\n",
    "                t_1d = t.flatten()\n",
    "                idx_1d = t_1d.argsort()[-k:][::-1]\n",
    "                x_idx, y_idx = np.unravel_index(idx_1d, t.shape)\n",
    "                temp = []\n",
    "                for x, y, in zip(x_idx, y_idx):\n",
    "                    temp.append(s[x]+[l[i][y]])\n",
    "                s = temp\n",
    "        return s\n",
    "    def top_k_paths_optimal(self,l,k):\n",
    "        s = [[] for _ in range(k)]\n",
    "        p_values=[]\n",
    "        for i in range(0,len(l)):\n",
    "            if i==0:\n",
    "                temp = []\n",
    "                if len(l[i])>k:\n",
    "                    v = random.sample(range(0,len(l[i])),k)\n",
    "                    for j in v:\n",
    "                        temp.append([l[i][j]])\n",
    "                else:\n",
    "                    for j in range(0,len(l[i])):\n",
    "                        temp.append([l[i][j]])\n",
    "                p_values = [0.5]*len(temp)\n",
    "                s=temp\n",
    "            else:\n",
    "                count = 0\n",
    "                for m in s:\n",
    "                    if m:\n",
    "                        count+=1\n",
    "                t = np.zeros(shape=(count,len(l[i]))) \n",
    "                for p in range(0,t.shape[0]):\n",
    "                    for q in range(0,t.shape[1]):\n",
    "                        t[p,q]=A_normalized[s[p][-1],l[i][q]]\n",
    "                t = (t.T * p_values).T\n",
    "                t_1d = t.flatten()\n",
    "                idx_1d = t_1d.argsort()[-k:][::-1]\n",
    "                x_idx, y_idx = np.unravel_index(idx_1d, t.shape)\n",
    "                temp = []\n",
    "                for x, y, in zip(x_idx, y_idx):\n",
    "                    temp.append(s[x]+[l[i][y]])\n",
    "                p_values = [t[x][y] for x, y, in zip(x_idx, y_idx)]\n",
    "                s = temp\n",
    "        return s,p_values        \n",
    "def main():\n",
    "    for i in result:\n",
    "        di=[]\n",
    "        #print i['sentence']\n",
    "        #print i['keys']\n",
    "        #print (\"Lemmas list\")\n",
    "        #print i['lemmas']\n",
    "        #print i[1]['lemmas']\n",
    "        for j in i[1]['lemmas']:\n",
    "            l=[]\n",
    "            for k in j:\n",
    "                if(k.encode(\"ascii\",\"ignore\") in main_x_list):\n",
    "                    l.append(main_x_list.index(k.encode(\"ascii\",\"ignore\")))\n",
    "                else:\n",
    "                    pass\n",
    "            di.append(l)\n",
    "        di = [x for x in di if x != []]\n",
    "        k=2\n",
    "        levels=len(di)\n",
    "        bs = beamsearch(k,levels,di)\n",
    "        g=[]\n",
    "        for i in bs.k_paths_greedy:\n",
    "            greedy_path=[main_x_list[x] for x in i]\n",
    "            g.append(greedy_path)\n",
    "        greedy_paths.append(g)\n",
    "        o=[]\n",
    "        for i in bs.k_paths_optimal:\n",
    "            optimal_path=[main_x_list[x] for x in i]\n",
    "            o.append(optimal_path)\n",
    "        optimal_paths.append(o)\n",
    "if __name__ == \"__main__\": main()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_paths=[]\n",
    "for i in result:\n",
    "    p=[]\n",
    "    for j in i[0]['lemmas']:\n",
    "        for k in j:\n",
    "            p.append(k)\n",
    "    actual_paths.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "count=0\n",
    "count1=0\n",
    "count2=0\n",
    "total=0\n",
    "a=[]\n",
    "for i in range(0,len(optimal_paths)):\n",
    "    if len(actual_paths[i]) == len(optimal_paths[i][0]) or len(actual_paths[i]) == len(optimal_paths[i][0]):\n",
    "        total+=1\n",
    "        if optimal_paths[i][0]==actual_paths[i]:\n",
    "            count+=1\n",
    "            count1+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(optimal_paths[i][0])\n",
    "            count2+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(actual_paths[i])\n",
    "        else:\n",
    "            try:\n",
    "                if optimal_paths[i][1] == actual_paths[i]:\n",
    "                    count+=1\n",
    "                    count1+=len(list(set(actual_paths[i]) & set(optimal_paths[i][1])))/len(optimal_paths[i][1])\n",
    "                    count2+=len(list(set(actual_paths[i]) & set(optimal_paths[i][1])))/len(actual_paths[i])\n",
    "                else:\n",
    "                    count1+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(optimal_paths[i][0])\n",
    "                    count2+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(actual_paths[i])\n",
    "            except:\n",
    "                count1+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(optimal_paths[i][0])\n",
    "                count2+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(actual_paths[i])\n",
    "    else:\n",
    "        count1+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(optimal_paths[i][0])\n",
    "        count2+=len(list(set(actual_paths[i]) & set(optimal_paths[i][0])))/len(actual_paths[i])\n",
    "        a.append([actual_paths[i],optimal_paths[i][0]])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7350427350427351"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198249855355993"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1/len(actual_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dd0655f2f892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/home/prithvi/Downloads/NLP Project/SKT_File/extras/sandhiRules.p'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unsupported pickle protocol: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPROTO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 3"
     ]
    }
   ],
   "source": [
    "input_path ='/home/prithvi/Downloads/NLP Project/SKT_File/extras/sandhiRules.p'\n",
    "pickle.load(open(input_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "for line in open('/home/prithvi/Downloads/movies.txt'):\n",
    "    rp=[line.split(\".json\")[0]]\n",
    "    with open('imdb_movies.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(rp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
